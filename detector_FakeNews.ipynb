{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/yxSqG3SL6ENl8iXM+ciT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK da google"
      ],
      "metadata": {
        "id": "2b_OUG8dorvk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8OvWnNBKfJE"
      },
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=\"SEU_API_KEY\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "TD2g16HUpJJ8"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "rZp-970vpfb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "-PXVZpXlpcOd",
        "outputId": "4700621b-ee33-41ef-833c-ab3443f2a29f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "FfVghDuFq-Am"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "5N5A78eTrdU9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o nosso modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "kOC-QolGsT4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "CJuVTP4Wr_sW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "função principal sobre funcionamento do programa"
      ],
      "metadata": {
        "id": "Ozo8SDob9jCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "IjNF4EYttxTn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Solicitando entrada do usuário\n",
        "prompt = input(\"Insira o texto do artigo ou o link: \")\n",
        "\n",
        "# Verificando se é um link e obtendo o texto do artigo\n",
        "if prompt.startswith(\"http\"):\n",
        "\n",
        "    text = prompt + \" - [Insira um sim ou não sobre o link se é fake news ou não, analise o site e verifique se é fake news, elabore argumento e forneça links e forneça links se comprova ou não]\"\n",
        "else:\n",
        "    text = prompt + \" - [Insira um sim ou não sobre o argumento se é fake news ou não, elabore argumento e forneça links se comprova ou não]\"\n",
        "\n",
        "# Enviando o texto para o modelo\n",
        "response = chat.send_message(text)\n",
        "\n",
        "# Exibindo a resposta\n",
        "print(\"Resposta do modelo:\", response.text)\n"
      ],
      "metadata": {
        "id": "NMRFJPHcuG5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}